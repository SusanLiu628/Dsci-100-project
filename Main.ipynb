{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123b886a-39f9-48e7-8ad3-19e8a94767b8",
   "metadata": {},
   "source": [
    "Predicting Spam with Capital Letter Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b67da-8db8-47d1-8746-c9dc4433550e",
   "metadata": {},
   "source": [
    "REMEMBER: upload both an html and .ipynb file to the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e582f446-ed9c-4624-899f-e2ff6a35b81e",
   "metadata": {},
   "source": [
    "## Question : Can the credibility of mail be catagorized based on the use of capital letters and keywords in its message content?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257cc702-a635-4196-bb70-7be6f4ba24b6",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "Spam mail, or unsolicited messages sent en mass to random recipients have grown in volume in recent years following the convenience and anonymity of the internet [Kaddoura et al., 2022]. Ranging from harmless business advertisements to scams taking advantage of vulnerable groups, this phenomenon imposes varying degrees of economic and emotional harm on a vast number of e-mail users [Kaddoura et al., 2022]. Attention grabbing words and an overuse of capital letters are common features of spam mail, [Mujtaba et al., 2017] and mail-filtering programs have long been proposed as a potential solution to reduce user interaction with spam mail [Kaddoura et al., 2022]. Since many of these programs use lexical and term-based features in identifying spam mail [Mujtaba et al., 2017], the reliability of these identifiers are important to the accuracy of spam mail detectors. We will be investigating if the legitimacy of mail can be categorized based on the use of capital letters and keywords in email using the UCI Machine Learing Repository's Spambase dataset which is composed of emails flagged as spam by recipients as well as personal and work-related non-spam emails. The dataset provides infomation regarding the longest run length of capital letters throughout the message (in the capital_run_length_longest column) as well percentage of certain characters in the message such as \"free\" and \"!\". We will be analyzing the accuracy of categorizing spam mail based on the percentage of the strings \"000\", \"free\" and \"credit\", as well as the longest run of capital letters in a message. Our exploratory data analysis showed that there was a significant difference in the mean value for these attributes between spam and non-spam e-mails, and are likely good identifiers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aead6c-9435-483c-9b91-fc927c9e967b",
   "metadata": {},
   "source": [
    "### Preliminary exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcee137-73cd-46c5-ac45-4f0df72d8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import ChainMap\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56290f82-a279-4206-b167-5f8bcd8cf42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\"spambase.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5f6be8-6599-4224-90a7-5090edf45150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_titles = pd.read_csv(\"spambase.names\", skiprows = 31)\n",
    "spam_titles_split = spam_titles[\"1\"].str.split(\":\", expand = True)\n",
    "spam_headers = spam_titles_split[[0]].to_dict()\n",
    "spam_headers = dict(ChainMap(*spam_headers.values()))\n",
    "\n",
    "spam = spam.rename(columns = spam_headers).rename(columns = {57: \"is_spam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df0ce71-6ef3-45cf-b2fb-b5578bd937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_train, spam_test = train_test_split(spam, train_size = 0.75, stratify = spam[\"is_spam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5b2d6-324b-480c-ab25-b00a4be19159",
   "metadata": {},
   "source": [
    "#### Identifying Predictor Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12abdcd2-a8ef-4033-a3df-25f4f2fe8ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>mean_value_spam</th>\n",
       "      <th>mean_value_non_spam</th>\n",
       "      <th>spam_non_spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>is_spam</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_freq_3d</td>\n",
       "      <td>0.113620</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>101.965694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>word_freq_000</td>\n",
       "      <td>0.247785</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>39.978296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>0.276586</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>39.830630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>word_freq_credit</td>\n",
       "      <td>0.214253</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>29.243035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_$</td>\n",
       "      <td>0.171753</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>16.558395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>word_freq_money</td>\n",
       "      <td>0.212428</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>14.449821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>word_freq_addresses</td>\n",
       "      <td>0.110007</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>11.974252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>6.575958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>word_freq_business</td>\n",
       "      <td>0.290338</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>6.048598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>word_freq_font</td>\n",
       "      <td>0.237027</td>\n",
       "      <td>0.041315</td>\n",
       "      <td>5.737052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>99.010302</td>\n",
       "      <td>18.534194</td>\n",
       "      <td>5.342034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word_freq_internet</td>\n",
       "      <td>0.207123</td>\n",
       "      <td>0.039455</td>\n",
       "      <td>5.249624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word_freq_receive</td>\n",
       "      <td>0.116431</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>5.031156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>0.526330</td>\n",
       "      <td>0.116377</td>\n",
       "      <td>4.522613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>word_freq_order</td>\n",
       "      <td>0.169772</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>4.483934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word_freq_over</td>\n",
       "      <td>0.180022</td>\n",
       "      <td>0.045916</td>\n",
       "      <td>3.920697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>8.869103</td>\n",
       "      <td>2.412104</td>\n",
       "      <td>3.676916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_freq_email</td>\n",
       "      <td>0.323422</td>\n",
       "      <td>0.092678</td>\n",
       "      <td>3.489729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>1.374422</td>\n",
       "      <td>0.451081</td>\n",
       "      <td>3.046954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     attribute  mean_value_spam  mean_value_non_spam  \\\n",
       "57                     is_spam         1.000000             0.000000   \n",
       "3                 word_freq_3d         0.113620             0.001114   \n",
       "22               word_freq_000         0.247785             0.006198   \n",
       "6             word_freq_remove         0.276586             0.006944   \n",
       "19            word_freq_credit         0.214253             0.007327   \n",
       "52                 char_freq_$         0.171753             0.010373   \n",
       "23             word_freq_money         0.212428             0.014701   \n",
       "14         word_freq_addresses         0.110007             0.009187   \n",
       "15              word_freq_free         0.523687             0.079637   \n",
       "16          word_freq_business         0.290338             0.048001   \n",
       "21              word_freq_font         0.237027             0.041315   \n",
       "55  capital_run_length_longest        99.010302            18.534194   \n",
       "7           word_freq_internet         0.207123             0.039455   \n",
       "10           word_freq_receive         0.116431             0.023142   \n",
       "51                 char_freq_!         0.526330             0.116377   \n",
       "8              word_freq_order         0.169772             0.037862   \n",
       "5               word_freq_over         0.180022             0.045916   \n",
       "54  capital_run_length_average         8.869103             2.412104   \n",
       "17             word_freq_email         0.323422             0.092678   \n",
       "20              word_freq_your         1.374422             0.451081   \n",
       "\n",
       "    spam_non_spam_ratio  \n",
       "57                  inf  \n",
       "3            101.965694  \n",
       "22            39.978296  \n",
       "6             39.830630  \n",
       "19            29.243035  \n",
       "52            16.558395  \n",
       "23            14.449821  \n",
       "14            11.974252  \n",
       "15             6.575958  \n",
       "16             6.048598  \n",
       "21             5.737052  \n",
       "55             5.342034  \n",
       "7              5.249624  \n",
       "10             5.031156  \n",
       "51             4.522613  \n",
       "8              4.483934  \n",
       "5              3.920697  \n",
       "54             3.676916  \n",
       "17             3.489729  \n",
       "20             3.046954  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_mail = spam_train[spam_train[\"is_spam\"] == 1]\n",
    "non_spam = spam_train[spam_train[\"is_spam\"] == 0]\n",
    "mean_spam = pd.DataFrame(spam_mail.mean().reset_index()).rename(columns = {\"index\": \"attribute\", 0: \"mean_value_spam\"})\n",
    "mean_non_spam = pd.DataFrame(non_spam.mean().reset_index()).rename(columns = {\"index\": \"attribute\", 0: \"mean_value_non_spam\"})\n",
    "mean_non_spam\n",
    "\n",
    "mean_val_compare = mean_spam.merge(mean_non_spam, on = \"attribute\")\n",
    "mean_val_compare = mean_val_compare.assign(spam_non_spam_ratio = mean_val_compare[\"mean_value_spam\"] / mean_val_compare[\"mean_value_non_spam\"])\n",
    "mean_val_compare = mean_val_compare.sort_values(by=\"spam_non_spam_ratio\", ascending=False)\n",
    "mean_val_compare.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31582e1-696c-438b-bae0-75c36eae7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reduce dataframes we will use to only the data we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0551b04-df3e-40fd-93f6-f0eafa681c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>mean_value_spam</th>\n",
       "      <th>mean_value_non_spam</th>\n",
       "      <th>spam_non_spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>word_freq_000</td>\n",
       "      <td>0.247785</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>39.978296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>word_freq_credit</td>\n",
       "      <td>0.214253</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>29.243035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>0.523687</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>6.575958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>99.010302</td>\n",
       "      <td>18.534194</td>\n",
       "      <td>5.342034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     attribute  mean_value_spam  mean_value_non_spam  \\\n",
       "22               word_freq_000         0.247785             0.006198   \n",
       "19            word_freq_credit         0.214253             0.007327   \n",
       "15              word_freq_free         0.523687             0.079637   \n",
       "55  capital_run_length_longest        99.010302            18.534194   \n",
       "\n",
       "    spam_non_spam_ratio  \n",
       "22            39.978296  \n",
       "19            29.243035  \n",
       "15             6.575958  \n",
       "55             5.342034  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train_predictors = spam_train[[\"word_freq_000\", \"word_freq_credit\", \"word_freq_free\", \"capital_run_length_longest\", \"is_spam\"]]\n",
    "mean_val_predictors = mean_val_compare[mean_val_compare[\"attribute\"].isin([\"word_freq_000\", \"word_freq_credit\", \"word_freq_free\", \"capital_run_length_longest\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ffdb79-f0e9-408f-9e04-e21e44e25ce4",
   "metadata": {},
   "source": [
    "#### Visualization of Predictor Variables \n",
    "Using scatter plots, we visualize the relationship between non-spam and spam mail and the predictor variables we chose.\n",
    "\n",
    "We will plot the word frequencies of \"000\" vs. \"credit\" as well as the word frequency of \"free\" vs. longest capital run length. In the plot, we will identify the points by spam and non-spam with a different colour and shape : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98c73cd-59b4-4dad-89a2-6073fa425b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "# !{sys.executable} -m pip uninstall rfc3986-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfa6a9-8b84-4f7a-b43d-3643b364e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install check-jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96d67fa5-645c-444b-ad69-68d3c7626f2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SchemaError",
     "evalue": "'#/definitions/TopLevelNormalizedHConcatSpec<GenericSpec>' is not a 'uri-reference'\n\nFailed validating 'format' in metaschema['properties']['$ref']:\n    {'format': 'uri-reference', 'type': 'string'}\n\nOn schema['$ref']:\n    '#/definitions/TopLevelNormalizedHConcatSpec<GenericSpec>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/altair/vegalite/v4/api.py:384\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTopLevelMixin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m jsonschema\u001b[38;5;241m.\u001b[39mValidationError:\n\u001b[1;32m    386\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/altair/utils/schemapi.py:338\u001b[0m, in \u001b[0;36mSchemaBase.to_dict\u001b[0;34m(self, validate, ignore, context)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m jsonschema\u001b[38;5;241m.\u001b[39mValidationError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SchemaValidationError(\u001b[38;5;28mself\u001b[39m, err)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/altair/utils/schemapi.py:443\u001b[0m, in \u001b[0;36mSchemaBase.validate\u001b[0;34m(cls, instance, schema)\u001b[0m\n\u001b[1;32m    441\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_schema\n\u001b[1;32m    442\u001b[0m resolver \u001b[38;5;241m=\u001b[39m jsonschema\u001b[38;5;241m.\u001b[39mRefResolver\u001b[38;5;241m.\u001b[39mfrom_schema(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_rootschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_schema)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolver\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jsonschema/validators.py:1117\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(instance, schema, cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m validator_for(schema)\n\u001b[0;32m-> 1117\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(schema, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1119\u001b[0m error \u001b[38;5;241m=\u001b[39m exceptions\u001b[38;5;241m.\u001b[39mbest_match(validator\u001b[38;5;241m.\u001b[39miter_errors(instance))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jsonschema/validators.py:231\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.check_schema\u001b[0;34m(cls, schema, format_checker)\u001b[0m\n\u001b[1;32m    226\u001b[0m validator \u001b[38;5;241m=\u001b[39m Validator(\n\u001b[1;32m    227\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mMETA_SCHEMA,\n\u001b[1;32m    228\u001b[0m     format_checker\u001b[38;5;241m=\u001b[39mformat_checker,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m error \u001b[38;5;129;01min\u001b[39;00m validator\u001b[38;5;241m.\u001b[39miter_errors(schema):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mSchemaError\u001b[38;5;241m.\u001b[39mcreate_from(error)\n",
      "\u001b[0;31mSchemaError\u001b[0m: '#/definitions/TopLevelNormalizedHConcatSpec<GenericSpec>' is not a 'uri-reference'\n\nFailed validating 'format' in metaschema['properties']['$ref']:\n    {'format': 'uri-reference', 'type': 'string'}\n\nOn schema['$ref']:\n    '#/definitions/TopLevelNormalizedHConcatSpec<GenericSpec>'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_and_credit_scatter_plot = (\n",
    "    alt.Chart(\n",
    "        spam_train_predictors, title=\"Word Frequency of \\\"000\\\" vs. \\'credit\\'\"\n",
    "    ).mark_point(opacity=0.5)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"word_freq_credit\",\n",
    "            title=\"Frequency of \\'credit\\'\",\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            \"word_freq_000\",\n",
    "            title=\"Frequency of \\'000\\'\",\n",
    "        ),\n",
    "        color=alt.Color(\"is_spam\", legend=alt.Legend(title=\"Spam by colour and shape\", orient=\"left\"), scale=alt.Scale(scheme='dark2')),\n",
    "        shape=\"is_spam\"\n",
    "    )\n",
    ")\n",
    "\n",
    "free_and_capital_scatter_plot = (\n",
    "    alt.Chart(\n",
    "        spam_train_predictors, title=\"Word Frequency of \\'free\\' vs. Capital Run Length\"\n",
    "    ).mark_point(opacity=0.5)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"word_freq_free\",\n",
    "            title=\"Frequency of \\'free\\'\",\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            \"capital_run_length_longest\",\n",
    "            title=\"Capital Run Length\",\n",
    "        ),\n",
    "        color=alt.Color(\"is_spam\", legend=alt.Legend(title=\"Spam by colour and shape\", orient=\"right\"), scale=alt.Scale(scheme='dark2')),\n",
    "        shape=\"is_spam\"\n",
    "    )\n",
    ")\n",
    "\n",
    "predictor_scatter_plots = alt.hconcat(zeros_and_credit_scatter_plot, free_and_capital_scatter_plot)\n",
    "\n",
    "predictor_scatter_plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db88d4-b0d0-480c-830c-2b6d69a4b1c3",
   "metadata": {},
   "source": [
    "Additionally, we will also plot the differences in mean value for the predictor variables between spam and non-spam mail with a bar plot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4af77a-b265-42eb-989d-adff1479c75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2255b6e01c2a4ae5beec28e2860ac47b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2255b6e01c2a4ae5beec28e2860ac47b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2255b6e01c2a4ae5beec28e2860ac47b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4c178d770ec980d142972bd230f8e1ee\"}, \"mark\": {\"type\": \"bar\", \"color\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"attribute\", \"sort\": \"-y\", \"title\": \"Predictor Variable\", \"type\": \"nominal\"}, \"y\": {\"field\": \"spam_non_spam_ratio\", \"title\": \"Mean Value\", \"type\": \"quantitative\"}}, \"title\": \"Mean Value of Predictor Values\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4c178d770ec980d142972bd230f8e1ee\": [{\"attribute\": \"word_freq_000\", \"mean_value_spam\": 0.247785136129507, \"mean_value_non_spam\": 0.0061979913916786235, \"spam_non_spam_ratio\": 39.97829626904314}, {\"attribute\": \"word_freq_credit\", \"mean_value_spam\": 0.21425312729948492, \"mean_value_non_spam\": 0.007326637972262076, \"spam_non_spam_ratio\": 29.243034541985832}, {\"attribute\": \"word_freq_free\", \"mean_value_spam\": 0.5236865342163356, \"mean_value_non_spam\": 0.07963653754184599, \"spam_non_spam_ratio\": 6.5759581014073865}, {\"attribute\": \"capital_run_length_longest\", \"mean_value_spam\": 99.0103016924209, \"mean_value_non_spam\": 18.534194165471067, \"spam_non_spam_ratio\": 5.342034339797499}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free_and_capital_scatter_plot = (\n",
    "#     alt.Chart(\n",
    "#         spam_train_predictors, title=\"Word Frequency of \\'free\\' vs. Capital Run Length\"\n",
    "#     ).mark_point()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             \"word_freq_free\",\n",
    "#             title=\"Frequency of \\'free\\'\",\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             \"capital_run_length_longest\",\n",
    "#             title=\"Capital Run Length\",\n",
    "#         ),\n",
    "#         # color=alt.Color(\"is_spam\", legend=alt.Legend(title=\"Spam by colour and shape\", orient=\"right\"), scale=alt.Scale(scheme='dark2')),\n",
    "#         # shape=\"is_spam\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# spam_bar_plot = (\n",
    "#     alt.Chart(\n",
    "#         mean_val_predictors, title=\"Mean Value of Predictor Values\"\n",
    "#     ).mark_bar()\n",
    "#     .encode(\n",
    "#         x=alt.X(\n",
    "#             \"attribute\",\n",
    "#             title=\"Predictor Variable\",\n",
    "#         ),\n",
    "#         y=alt.Y(\n",
    "#             \"mean_value_spam\",\n",
    "#             title=\"Mean Value\",\n",
    "#         ),\n",
    "#     )\n",
    "# )\n",
    "\n",
    "ratio_bar_plot = (\n",
    "    alt.Chart(\n",
    "        mean_val_predictors, title=\"Mean Value of Predictor Values\"\n",
    "    ).mark_bar(color='orange')\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"attribute\",\n",
    "            title=\"Predictor Variable\",\n",
    "            sort='-y'\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            \"spam_non_spam_ratio\",\n",
    "            title=\"Mean Value\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "ratio_bar_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01cac3-4d00-46b7-9995-6c96f6a66cf1",
   "metadata": {},
   "source": [
    "### Methods of analysis\n",
    "We will use classification with a model that we build and test. We will then use the results to assess how well certain certain attributes of an e-mail message can be used to correctly classify an e-mail as spam and non-spam.\n",
    "We chose four predictor variables we thought were indicative of whether an e-mail may be spam. We chose them because the mean values (mean of all the observed e-mails in the data set) of these variables showed large differences for spam and non-spam. Therefore, we believe high values for these variables are characteristic of spam mail and allow us to build an accurate prediction model using the `sklearn` package and the **KNN-Algorithm**. \n",
    "We will also verify the accuracy of our model by putting aside a testing set. To visualize our results, we will use line plots showing the accuracy of our model for varying values of `K`. We will also use multiple scattor plots showing trends between spam and non-spam mail and our predictor variables, where spam and non-spam would be identified by colour and shape. \n",
    "One plot will show this trend using our training set and correct labels, and the other will use our testing set and predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20979c-081f-4041-b2c3-931943c3c403",
   "metadata": {},
   "source": [
    "Works Cited:\n",
    "\n",
    "    Kaddoura, S., Chandrasekaran, G., Elena Popescu, D., & Duraisamy, J. H. (2022). A systematic literature review on spam content detection and classification. PeerJ Computer Science, 8, e830. https://doi.org/10.7717/peerj-cs.830\n",
    "\n",
    "    Mujtaba, G., Shuib, L., Raj, R. G., Majeed, N., & Al-Garadi, M. A. (2017). Email Classification Research Trends: Review and Open Issues. IEEE Access, 5, 9044–9064. https://doi.org/10.1109/access.2017.2702187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c57b20-18c6-4b6e-b409-e9736ddcdfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2002b1-5405-490f-8c5b-79c4566318e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
